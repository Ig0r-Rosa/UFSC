{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOMdAB+kbCpaAAaZ95SG70+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":14,"metadata":{"id":"vZ45xyw_7EaG","executionInfo":{"status":"ok","timestamp":1687804766128,"user_tz":180,"elapsed":1,"user":{"displayName":"Igor de Matos da Rosa","userId":"12975805620298073653"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import gym"]},{"cell_type":"code","source":["# Crie o ambiente personalizado\n","class CustomEnv(gym.Env):\n","    def __init__(self):\n","        self.grid_size = 5  # Tamanho da grade\n","        self.start_state = (0, 0)  # Estado inicial\n","        self.goal_state = (4, 4)  # Estado objetivo\n","        self.current_state = self.start_state  # Estado atual\n","        self.action_space = gym.spaces.Discrete(4)  # Espaço de ação (cima, baixo, esquerda, direita)\n","        self.observation_space = gym.spaces.Tuple((\n","            gym.spaces.Discrete(self.grid_size),\n","            gym.spaces.Discrete(self.grid_size)\n","        ))  # Espaço de observação\n","\n","    def reset(self):\n","        self.current_state = self.start_state\n","        return self.current_state\n","\n","    def step(self, action):\n","        x, y = self.current_state\n","\n","        if action == 0:  # Cima\n","            x = max(0, x - 1)\n","        elif action == 1:  # Baixo\n","            x = min(self.grid_size - 1, x + 1)\n","        elif action == 2:  # Esquerda\n","            y = max(0, y - 1)\n","        elif action == 3:  # Direita\n","            y = min(self.grid_size - 1, y + 1)\n","\n","        self.current_state = (x, y)\n","\n","        done = (self.current_state == self.goal_state)\n","        reward = 1 if done else 0\n","\n","        return self.current_state, reward, done, {}\n","\n","    def render(self):\n","        grid = np.zeros((self.grid_size, self.grid_size), dtype=np.int8)\n","        grid[self.goal_state[0], self.goal_state[1]] = 2\n","        grid[self.current_state[0], self.current_state[1]] = 1\n","\n","        for row in grid:\n","            print(' '.join(map(str, row)))\n","\n","\n","# Algoritmo Q-Learning\n","def q_learning(env, num_episodes, alpha, gamma, epsilon):\n","    q_table = np.zeros((env.grid_size, env.grid_size, env.action_space.n))\n","\n","    for episode in range(num_episodes):\n","        state = env.reset()\n","        done = False\n","\n","        while not done:\n","            if np.random.rand() < epsilon:\n","                action = env.action_space.sample()\n","            else:\n","                action = np.argmax(q_table[state])\n","\n","            next_state, reward, done, _ = env.step(action)\n","\n","            q_value = q_table[state][action]\n","            next_max_q = np.max(q_table[next_state])\n","\n","            q_table[state][action] += alpha * (reward + gamma * next_max_q - q_value)\n","            state = next_state\n","\n","    return q_table\n","\n","\n","# Função principal\n","def main():\n","    env = CustomEnv()\n","\n","    # Parâmetros do Q-Learning\n","    num_episodes = 1000\n","    alpha = 0.5\n","    gamma = 0.9\n","    epsilon = 0.1\n","\n","    # Executa o algoritmo Q-Learning\n","    q_table = q_learning(env, num_episodes, alpha, gamma, epsilon)\n","\n","    # Imprime a tabela Q final\n","    print(\"Tabela Q final:\")\n","    print(q_table)\n","\n","    # Testa a política aprendida\n","    state = env.reset()\n","    done = False\n","\n","    print(\"Caminho encontrado:\")\n","    env.render()\n","\n","    while not done:\n","        action = np.argmax(q_table[state])\n","        state, _, done, _ = env.step(action)\n","        env.render()\n","\n","    print(\"Chegou ao objetivo!\")\n","\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J_p2aJqX9MpM","executionInfo":{"status":"ok","timestamp":1687808617796,"user_tz":180,"elapsed":231691,"user":{"displayName":"Igor de Matos da Rosa","userId":"12975805620298073653"}},"outputId":"698e8b6a-c6eb-43bb-f75c-de68e081e20b"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Tabela Q final:\n","[[[0.43046721 0.38742049 0.43046721 0.4782969 ]\n","  [0.4782969  0.43046679 0.43046711 0.531441  ]\n","  [0.531441   0.47829686 0.4782969  0.59049   ]\n","  [0.59049    0.6561     0.53144087 0.531441  ]\n","  [0.26565557 0.         0.59049    0.39857974]]\n","\n"," [[0.43046721 0.         0.         0.21523319]\n","  [0.47829687 0.         0.33889831 0.        ]\n","  [0.531441   0.24198014 0.21438054 0.492075  ]\n","  [0.59049    0.71562669 0.47829504 0.729     ]\n","  [0.531441   0.81       0.6561     0.72899999]]\n","\n"," [[0.         0.         0.         0.        ]\n","  [0.         0.         0.         0.        ]\n","  [0.41839296 0.         0.         0.36165234]\n","  [0.6561     0.45605357 0.16132006 0.80990112]\n","  [0.729      0.9        0.6141825  0.81      ]]\n","\n"," [[0.         0.         0.         0.        ]\n","  [0.         0.         0.         0.        ]\n","  [0.         0.         0.         0.        ]\n","  [0.7235147  0.09675943 0.         0.675     ]\n","  [0.81       1.         0.63183103 0.89999999]]\n","\n"," [[0.         0.         0.         0.        ]\n","  [0.         0.         0.         0.        ]\n","  [0.         0.         0.         0.        ]\n","  [0.37323098 0.         0.         0.        ]\n","  [0.         0.         0.         0.        ]]]\n","Caminho encontrado:\n","1 0 0 0 0\n","0 0 0 0 0\n","0 0 0 0 0\n","0 0 0 0 0\n","0 0 0 0 2\n","0 1 0 0 0\n","0 0 0 0 0\n","0 0 0 0 0\n","0 0 0 0 0\n","0 0 0 0 2\n","0 0 1 0 0\n","0 0 0 0 0\n","0 0 0 0 0\n","0 0 0 0 0\n","0 0 0 0 2\n","0 0 0 1 0\n","0 0 0 0 0\n","0 0 0 0 0\n","0 0 0 0 0\n","0 0 0 0 2\n","0 0 0 0 0\n","0 0 0 1 0\n","0 0 0 0 0\n","0 0 0 0 0\n","0 0 0 0 2\n","0 0 0 0 0\n","0 0 0 0 1\n","0 0 0 0 0\n","0 0 0 0 0\n","0 0 0 0 2\n","0 0 0 0 0\n","0 0 0 0 0\n","0 0 0 0 1\n","0 0 0 0 0\n","0 0 0 0 2\n","0 0 0 0 0\n","0 0 0 0 0\n","0 0 0 0 0\n","0 0 0 0 1\n","0 0 0 0 2\n","0 0 0 0 0\n","0 0 0 0 0\n","0 0 0 0 0\n","0 0 0 0 0\n","0 0 0 0 1\n","Chegou ao objetivo!\n"]}]}]}